services:
  postgres:
    image: postgres:15
    environment:
      POSTGRES_USER: ascentrix
      POSTGRES_PASSWORD: ascentrixpw
      POSTGRES_DB: ascentrix
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ascentrix"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7
    restart: always
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  qdrant:
    image: qdrant/qdrant:v1.7.3
    volumes:
      - ./data/qdrant:/qdrant/storage
    ports:
      - "6333:6333"
    restart: always
    healthcheck:
      test:
        [
          "CMD",
          "/bin/bash",
          "-c",
          "exec 3<>/dev/tcp/127.0.0.1/6333 && printf 'GET /healthz HTTP/1.0\\r\\n\\r\\n' >&3 && timeout 5 cat <&3 | grep -q '200'",
        ]
      interval: 15s
      timeout: 5s
      retries: 5

  api:
    image: python:3.12-slim
    working_dir: /workspace
    volumes:
      - .:/workspace
      - api_deps:/deps
    extra_hosts:
      - "host.docker.internal:host-gateway"
    environment:
      PYTHONUNBUFFERED: "1"
      PYTHONPATH: /workspace:/deps
      GODMODE_REPO_ROOT: /workspace
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL}
      LLM_BACKEND_DEFAULT: ${LLM_BACKEND_DEFAULT}
      LLM_MODEL_QWEN: ${LLM_MODEL_QWEN}
      LLM_MODEL_PHI: ${LLM_MODEL_PHI}
      LLM_MODEL_MISTRAL: ${LLM_MODEL_MISTRAL}
      LLM_MODEL_LLAMA: ${LLM_MODEL_LLAMA}
      LLM_MODEL_OLLAMA_DEFAULT: ${LLM_MODEL_OLLAMA_DEFAULT}
      LLM_MODEL_OPENAI: ${LLM_MODEL_OPENAI}
    command: >
      bash -c "if [ ! -f /deps/.deps-installed ]; then
                  pip install --no-cache-dir -r api/requirements.txt -t /deps &&
                  touch /deps/.deps-installed;
                fi &&
                python -m uvicorn api.app:app --host 0.0.0.0 --port 5051"
    ports:
      - "${GODMODE_API_PORT_HOST:-5051}:5051"
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    restart: always
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import urllib.request; urllib.request.urlopen('http://127.0.0.1:5051/health', timeout=5)",
        ]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 180s

  hud:
    image: nginx:1.27-alpine
    volumes:
      - ./hud:/usr/share/nginx/html:ro
      - ./hud/nginx.conf:/etc/nginx/conf.d/default.conf:ro
    ports:
      - "${GODMODE_HUD_PORT_HOST:-5052}:80"
    restart: always
    healthcheck:
      test: ["CMD-SHELL", "wget -q --spider http://127.0.0.1:80/health || exit 1"]
      interval: 30s
      timeout: 5s
      retries: 5

  autopilot:
    build:
      context: .
      dockerfile: Dockerfile.autopilot
    working_dir: /workspace/api
    volumes:
      - .:/workspace
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      GODMODE_REPO_ROOT: /workspace
      PYTHONUNBUFFERED: "1"
      OLLAMA_BASE_URL: ${OLLAMA_BASE_URL}
      LLM_BACKEND_DEFAULT: ${LLM_BACKEND_DEFAULT}
      LLM_MODEL_QWEN: ${LLM_MODEL_QWEN}
      LLM_MODEL_PHI: ${LLM_MODEL_PHI}
      LLM_MODEL_MISTRAL: ${LLM_MODEL_MISTRAL}
      LLM_MODEL_LLAMA: ${LLM_MODEL_LLAMA}
      LLM_MODEL_OLLAMA_DEFAULT: ${LLM_MODEL_OLLAMA_DEFAULT}
      LLM_MODEL_OPENAI: ${LLM_MODEL_OPENAI}
    command: python autopilot.py
    depends_on:
      api:
        condition: service_healthy
    restart: unless-stopped

volumes:
  api_deps:
